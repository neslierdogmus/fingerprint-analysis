{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# import modules and packages\n","from pathlib import Path\n","import random\n","import numpy as np\n","\n","import torch\n","import torch.optim as optim\n","\n","from foe_fingerprint_dataset import FOEFingerprintDataset\n","from foe_orientation import FOEOrientation\n","from foe_results import FOEResults\n","from functions import (create_dataloaders, init_model, train_epoch, val_epoch,\n","                       save_model)\n","\n","# from IPython import get_ipython\n","# get_ipython().run_line_magic('matplotlib', 'widget')\n","\n","\n","def angle_loss(y, ye):\n","    delta_sqr = [torch.min(torch.abs(yi-yei), np.pi-torch.abs(yi-yei))\n","                 for (yi, yei) in zip(y, ye)]\n","    return torch.mean(torch.stack(delta_sqr))"]},{"cell_type":"code","execution_count":2,"metadata":{"tags":["parameters"]},"outputs":[],"source":["# parameters\n","# dataset_dir = '../datasets/Finger/FOESamples'\n","# output_dir = '../results'\n","# use_cpu = False\n","# seed = 0\n","# split_id = 2\n","# num_folds = 5\n","\n","# patch_size = 64\n","# batch_size = 64\n","# hflip = True\n","# rotate = True\n","\n","# num_classes = 36\n","# num_epochs = 100\n","# learning_rate = 0.0001\n","# approach = 'ae_mlp'\n","\n","# encoded_space_dim = 512\n","# train_with_bad = True\n","# ae_num_epochs = 300\n","# ae_learning_rate = 0.1\n","# file_id = 'default_file_id'\n","\n","dataset_dir = ''\n","output_dir = ''\n","use_cpu = ''\n","seed = ''\n","split_id = ''\n","num_folds = ''\n","\n","patch_size = ''\n","batch_size = ''\n","hflip = ''\n","rotate = ''\n","\n","num_classes = ''\n","num_epochs = ''\n","learning_rate = ''\n","approach = ''\n","\n","encoded_space_dim = ''\n","train_with_bad = ''\n","ae_num_epochs = ''\n","ae_learning_rate = ''\n","file_id = ''"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'patch_size': 64, 'batch_size': 64, 'hflip': True, 'rotate': True, 'num_classes': 36, 'num_epochs': 100, 'learning_rate': 0.0001, 'approach': 'ae_mlp', 'encoded_space_dim': 512, 'train_with_bad': True, 'ae_num_epochs': 300, 'ae_learning_rate': 0.1}\n","Using cuda...\n","Patch size: 64\n","Batch size: 64\n"]}],"source":["# parse and configure the experiment parameters\n","args = dict(((k, eval(k)) for k in ('patch_size', 'batch_size', 'hflip',\n","                                    'rotate', 'num_classes', 'num_epochs',\n","                                    'learning_rate', 'approach',\n","                                    'encoded_space_dim', 'train_with_bad',\n","                                    'ae_num_epochs', 'ae_learning_rate')))\n","print(args)\n","\n","dataset_dir = Path(dataset_dir)\n","output_dir = Path(output_dir)\n","\n","models_dir = output_dir.joinpath('models')\n","splits_dir = output_dir.joinpath('splits')\n","logs_dir = output_dir.joinpath('logs')\n","results_dir = output_dir.joinpath('results')\n","\n","output_dir.mkdir(parents=True, exist_ok=True)\n","models_dir.mkdir(parents=True, exist_ok=True)\n","splits_dir.mkdir(parents=True, exist_ok=True)\n","logs_dir.mkdir(parents=True, exist_ok=True)\n","results_dir.mkdir(parents=True, exist_ok=True)\n","\n","use_gpu = torch.cuda.is_available() and not use_cpu\n","device = 'cuda' if use_gpu else 'cpu'\n","\n","print('Using {}...'.format(device))\n","print('Patch size: {}'.format(patch_size))\n","print('Batch size: {}'.format(batch_size))\n","\n","if seed is not None:\n","    seed = int(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    # torch.set_deterministic(True)\n","\n","NUM_WORKERS = 4"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Split indices with id 2 loaded. Number of folds ignored.\n","Split indices with id 2 loaded. Number of folds ignored.\n","* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n","Experiments for fold 0 starts...\n","Training and validating with:\n","        Autoencoder training set size: 76728\n","        Orientation estimation training set size: 76728\n","        Validation set size (good): 2996\n","        Validation set size (bad): 15034\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m~/foe/notebooks/experiment.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/csigb/foe/notebooks/experiment.py?line=145'>146</a>\u001b[0m                                                    gamma=0.1)\n\u001b[1;32m     <a href='file:///home/csigb/foe/notebooks/experiment.py?line=146'>147</a>\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> <a href='file:///home/csigb/foe/notebooks/experiment.py?line=147'>148</a>\u001b[0;31m             train_loss = train_epoch(ae, ae_train_loader, loss_fn, optimizer,\n\u001b[0m\u001b[1;32m     <a href='file:///home/csigb/foe/notebooks/experiment.py?line=148'>149</a>\u001b[0m                                      is_ae=True)\n\u001b[1;32m     <a href='file:///home/csigb/foe/notebooks/experiment.py?line=149'>150</a>\u001b[0m             \u001b[0mval_loss_gd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_gd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_ae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/src/functions.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, loss_fn, optimizer, encoder, is_ae, results)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_in_radians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_ae\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/foe/env/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# configure fingerprint patch dataset in folds and run the experiments\n","\n","fpd_gd = FOEFingerprintDataset(dataset_dir, 'good')\n","fpd_gd.set_split_indices(splits_dir, split_id, num_folds)\n","\n","fpd_bd = FOEFingerprintDataset(dataset_dir, 'bad')\n","fpd_bd.set_split_indices(splits_dir, split_id, num_folds)\n","\n","RMSE = []\n","for fold_id in range(num_folds):\n","    print('* '*40)\n","    print('Experiments for fold {} starts...'.format(fold_id))\n","\n","    ae_train_loader = train_loader = val_loader = None\n","    val_loader_gd = val_loader_bd = None\n","\n","    (ae_train_loader, train_loader, val_loader_gd, val_loader_bd,\n","     val_loader) = create_dataloaders(fpd_gd, fpd_bd, fold_id, NUM_WORKERS,\n","                                      use_gpu, args)\n","    num_val_gd = len(val_loader_gd.dataset)\n","    num_val_bd = len(val_loader_bd.dataset)\n","\n","    encoder = None\n","    if approach == 'ae_mlp':\n","        ae, metrics = init_model('ae', models_dir, file_id, fold_id,\n","                                 device, args)\n","        n_epochs = ae_num_epochs - len(metrics.data['train_loss'])\n","        loss_fn = torch.nn.MSELoss(reduction='sum')\n","        optimizer = optim.Adam(ae.parameters(), lr=ae_learning_rate)\n","        scheduler_array = [int(0.7 * ae_num_epochs),\n","                           int(0.9 * ae_num_epochs)]\n","        scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                   scheduler_array,\n","                                                   gamma=0.1)\n","        for e in range(1, n_epochs+1):\n","            train_loss = train_epoch(ae, ae_train_loader, loss_fn, optimizer,\n","                                     is_ae=True)\n","            val_loss_gd = val_epoch(ae, val_loader_gd, loss_fn, is_ae=True)\n","            val_loss_bd = val_epoch(ae, val_loader_bd, loss_fn, is_ae=True)\n","            val_loss = ((num_val_gd * val_loss_gd + num_val_bd * val_loss_bd) /\n","                        (num_val_gd + num_val_bd))\n","            scheduler.step()\n","\n","            print('EPOCH {}/{}\\tLOSS for train/good val/bad val: '\n","                  '{:.3f} / {:.3f} / {:.3f} / {:.3f}'\n","                  .format(e, n_epochs, train_loss, val_loss,\n","                          val_loss_gd, val_loss_bd))\n","\n","            metrics.append(train_loss, val_loss, val_loss_gd, val_loss_bd)\n","        metrics.plot()\n","        ae.plot_outputs(val_loader_gd.dataset, 5)\n","        ae.plot_outputs(val_loader_bd.dataset, 5)\n","        if n_epochs > 0:\n","            save_model(ae)\n","            metrics.save()\n","        encoder = ae.encoder\n","\n","        model, metrics = init_model('mlp', models_dir, file_id, fold_id,\n","                                    device, args)\n","        loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler_array = [int(0.4 * num_epochs),\n","                           int(0.75 * num_epochs)]\n","        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, scheduler_array,\n","                                                   gamma=0.1)\n","    elif approach == 'cnn':\n","        model, metrics = init_model('cnn', models_dir, file_id, fold_id,\n","                                    device, args)\n","        loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler_array = [int(0.4 * num_epochs),\n","                           int(0.75 * num_epochs)]\n","        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, scheduler_array,\n","                                                   gamma=0.1)\n","    else:\n","        raise Exception('The \"approach\" parameter should'\n","                        ' either be \"ae_mlp\" or \"cnn\"!')\n","\n","    estimator = None\n","    if num_classes > 1:\n","        estimator = FOEOrientation.radians_from_marginalization\n","\n","    n_epochs = num_epochs - len(metrics.data['train_loss'])\n","    for e in range(1, n_epochs+1):\n","        results = FOEResults()\n","        results.set_fold(fold_id)\n","\n","        train_loss = train_epoch(model, train_loader, loss_fn, optimizer,\n","                                 encoder=encoder, results=results)\n","        val_loss_gd = val_epoch(model, val_loader_gd, loss_fn,\n","                                encoder=encoder, results=results)\n","        val_loss_bd = val_epoch(model, val_loader_bd, loss_fn,\n","                                encoder=encoder, results=results)\n","        val_loss = ((num_val_gd * val_loss_gd + num_val_bd * val_loss_bd) /\n","                    (num_val_gd + num_val_bd))\n","\n","        metrics.append(train_loss, val_loss, val_loss_gd, val_loss_bd)\n","        scheduler.step()\n","\n","        print('EPOCH {}/{}\\tLOSS for train/good val/bad val:\\t'\n","              '{:.3f} / {:.3f} / {:.3f} / {:.3f}'\n","              .format(e, n_epochs, train_loss, val_loss,\n","                      val_loss_gd, val_loss_bd))\n","\n","        if e % 10 == 1 or e == n_epochs:\n","            rmse_val = results.compute_classification_rmse(fold_id, estimator)\n","            rmse_val = [rmse / np.pi * 180 for rmse in rmse_val]\n","            print('RMSE for good train/bad train good val/bad val:\\t\\t'\n","                  '{:3.1f}° / {:3.1f}° / {:3.1f}° / {:3.1f}°'\n","                  ''.format(*rmse_val))\n","\n","            if num_classes > 1:\n","                acc_val = results.compute_classification_acc(fold_id)\n","                acc_val = [acc * 100 for acc in acc_val]\n","                print('ACC for good train/bad train good val/bad val:\\t\\t'\n","                      '{:3.1f}% / {:3.1f}% / {:3.1f}% / {:3.1f}%'\n","                      ''.format(*acc_val))\n","    metrics.plot()\n","    if n_epochs > 0:\n","        save_model(model)\n","        metrics.save()\n","    else:\n","        results = FOEResults()\n","        results.set_fold(fold_id)\n","        train_loss = val_epoch(model, train_loader, loss_fn,\n","                               encoder=encoder, results=results, is_tr=True)\n","        val_loss_gd = val_epoch(model, val_loader_gd, loss_fn,\n","                                encoder=encoder, results=results)\n","        val_loss_bd = val_epoch(model, val_loader_bd, loss_fn,\n","                                encoder=encoder, results=results)\n","        val_loss = ((num_val_gd * val_loss_gd + num_val_bd * val_loss_bd) /\n","                    (num_val_gd + num_val_bd))\n","\n","        print('Final LOSS for train/good val/bad val:\\t'\n","              '{:.3f} / {:.3f} / {:.3f} / {:.3f}'\n","              .format(train_loss, val_loss, val_loss_gd, val_loss_bd))\n","\n","        rmse_val = results.compute_classification_rmse(fold_id, estimator)\n","        rmse_val = [rmse / np.pi * 180 for rmse in rmse_val]\n","        print('RMSE for good train/bad train good val/bad val:\\t\\t'\n","              '{:3.1f}° / {:3.1f}° / {:3.1f}° / {:3.1f}°'.format(*rmse_val))\n","\n","        if num_classes > 1:\n","            acc_val = results.compute_classification_acc(fold_id)\n","            acc_val = [acc * 100 for acc in acc_val]\n","            print('ACC for good train/bad train good val/bad val:\\t\\t'\n","                  '{:3.1f}% / {:3.1f}% / {:3.1f}% / {:3.1f}%'.format(*acc_val))\n","    RMSE.append(rmse_val)\n","\n","RMSE_mean = np.array(RMSE).mean(0)\n","RMSE_std = np.array(RMSE).std(0)\n","\n","print('FINAL RESULTS:\\n\\t'\n","      'Train good rmse: {:.1f}° ± {:.1f}°\\n\\t'\n","      'Train bad rmse: {:.1f}° ± {:.1f}°\\n\\t'\n","      'Val good rmse: {:.1f}° ± {:.1f}°\\n\\t'\n","      'Val bad rmse: {:.1f}° ± {:.1f}°\\n'\n","      .format(RMSE_mean[0], RMSE_std[0], RMSE_mean[1], RMSE_std[1],\n","              RMSE_mean[2], RMSE_std[2], RMSE_mean[3], RMSE_std[3]))"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
