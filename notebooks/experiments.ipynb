{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fde725-4b43-4f1b-a603-d597f51fadc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'foe_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8172/861967863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfoe_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFOEDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'foe_dataset'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from foe_dataset import FOEDataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "\n",
    "real_path = '../datasets/Finger/FOESamples'\n",
    "synth_path = '../datasets/Finger/synfin/v1'\n",
    "\n",
    "dataset = FOEDataset(real_path, patch_size=27, synth=False, subset=\"all\")\n",
    "# img = plt.imread(os.path.join(real_path,\"Good\",\"110.bmp\"))\n",
    "# fg = np.loadtxt(os.path.join(real_path,\"Good\",\"110.fg\"),skiprows=1)\n",
    "# gt = dataset.read_gt(os.path.join(real_path,\"Good\",\"110.gt\"))\n",
    "# X, Y, PATCH, LABEL, ANGLE = dataset.extract_patch_data(img, fg, gt)\n",
    "# dataset.plot_grid(img, patch_data)\n",
    "# plt.figure()\n",
    "# plt.hist(ANGLE)\n",
    "# for i in range(2000,2050):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(PATCH[i]), print(LABEL[i], ANGLE[i])\n",
    "\n",
    "# dataset = FOEDataset(synth_path, patch_size=27, synth=True)\n",
    "# img = plt.imread(os.path.join(synth_path,\"110.png\"))\n",
    "# fg = np.loadtxt(os.path.join(synth_path,\"110.fg\"),skiprows=1)\n",
    "# gt = dataset.read_gt(os.path.join(synth_path,\"110.gt\"))\n",
    "# dataset.plot_grid(img,dataset.extract_patch_data(img, fg, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aff7ac-0f4b-49bd-aa9f-4b523b3e206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_layers = torch.nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            torch.nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4 * 3 * 3, 512),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self,m):\n",
    "        if type(m) == torch.nn.Linear:\n",
    "            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36890b09-c291-4a4d-b6ae-82d7ad48fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = torch.stack(X)\n",
    "        y = torch.tensor(y)\n",
    "        y = y.view((-1, 1))\n",
    "        idx = torch.randperm(X.size()[0])\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        train_loss += loss.item()\n",
    "        #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= len(dataloader)\n",
    "    #correct /= len(dataloader.dataset)\n",
    "    print(f\"Training Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "    return[train_loss, correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde38acb-e05d-4fdb-a70d-072f50d1290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    predd, yy = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = torch.stack(X)\n",
    "            y = torch.tensor(y)\n",
    "            y = y.view((-1, 1))\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            predd.append(pred)\n",
    "            yy.append(y)\n",
    "            test_loss += loss_fn(pred, y.float()).item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= len(dataloader)\n",
    "    #correct /= len(dataloader.dataset)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return[test_loss, correct, predd, yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452c99a-5fc3-437b-be2f-ad509858bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "N = len(dataset)\n",
    "batch_size = 1\n",
    "train_size = round(N*0.8)\n",
    "val_size = round(N*0.2)\n",
    "test_size = round(N*0.2)\n",
    "training_data, validation_data = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "folds = 1\n",
    "#test_dataloader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "for f in range(folds):\n",
    "    model = NeuralNetwork().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.8)\n",
    "    #training_data, validation_data = torch.utils.data.random_split(training_validation_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    train_dataloader =  torch.utils.data.DataLoader(training_data, batch_size=batch_size)\n",
    "    val_dataloader =  torch.utils.data.DataLoader(validation_data, batch_size=batch_size)\n",
    "\n",
    "    epochs = 50\n",
    "    train_res = []\n",
    "    test_res = []\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_ret = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_ret = test(val_dataloader, model)\n",
    "        train_res.append(train_ret)\n",
    "        test_res.append(test_ret)\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4c1b7-4da9-4dd9-87cb-72a056a00b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_res = np.array(train_res)\n",
    "test_res = np.array(test_res)\n",
    "plt.figure()\n",
    "plt.plot(train_res[:,0])\n",
    "plt.plot(test_res[:,0])\n",
    "# plt.figure()\n",
    "# plt.plot(train_res[:,1])\n",
    "# plt.plot(test_res[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324768f-193e-46c3-b1fa-ed8fa58ee7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, correct, predd, yy = test(val_dataloader, model)\n",
    "aaa = np.array([])\n",
    "bbb = np.array([])\n",
    "for p in predd: aaa = np.append(aaa, p.cpu().data.numpy().flatten())\n",
    "for y in yy: bbb = np.append(bbb, y.cpu().data.numpy().flatten())\n",
    "ccc = np.power(np.mean(np.power((aaa-bbb),2)),0.5)\n",
    "\n",
    "print(aaa.shape, bbb.shape, test_loss, ccc*180)\n",
    "print(predd[0].transpose(0,1).max())\n",
    "print(predd[0].transpose(0,1).min())\n",
    "print(yy[0].transpose(0,1).max())\n",
    "print(yy[0].transpose(0,1).min())\n",
    "\n",
    "plt.figure()\n",
    "hist_data = plt.hist(np.abs((aaa-bbb))*180,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac7fea-e6a8-41cc-be0b-1cbddc072c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
