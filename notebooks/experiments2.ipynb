{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fde725-4b43-4f1b-a603-d597f51fadc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/Finger/FOESamples/Bad/00.bmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csigb/app/env/lib/python3.9/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/Finger/FOESamples/Bad/01.bmp\n",
      "../datasets/Finger/FOESamples/Bad/02.bmp\n",
      "../datasets/Finger/FOESamples/Bad/03.bmp\n",
      "../datasets/Finger/FOESamples/Bad/04.bmp\n",
      "../datasets/Finger/FOESamples/Bad/05.bmp\n",
      "../datasets/Finger/FOESamples/Bad/06.bmp\n",
      "../datasets/Finger/FOESamples/Bad/07.bmp\n",
      "../datasets/Finger/FOESamples/Bad/08.bmp\n",
      "../datasets/Finger/FOESamples/Bad/09.bmp\n",
      "../datasets/Finger/FOESamples/Bad/10.bmp\n",
      "../datasets/Finger/FOESamples/Bad/11.bmp\n",
      "../datasets/Finger/FOESamples/Bad/12.bmp\n",
      "../datasets/Finger/FOESamples/Bad/13.bmp\n",
      "../datasets/Finger/FOESamples/Bad/14.bmp\n",
      "../datasets/Finger/FOESamples/Bad/15.bmp\n",
      "../datasets/Finger/FOESamples/Bad/16.bmp\n",
      "../datasets/Finger/FOESamples/Bad/17.bmp\n",
      "../datasets/Finger/FOESamples/Bad/18.bmp\n",
      "../datasets/Finger/FOESamples/Bad/19.bmp\n",
      "../datasets/Finger/FOESamples/Bad/20.bmp\n",
      "../datasets/Finger/FOESamples/Bad/21.bmp\n",
      "../datasets/Finger/FOESamples/Bad/22.bmp\n",
      "../datasets/Finger/FOESamples/Bad/23.bmp\n",
      "../datasets/Finger/FOESamples/Bad/24.bmp\n",
      "../datasets/Finger/FOESamples/Bad/25.bmp\n",
      "../datasets/Finger/FOESamples/Bad/26.bmp\n",
      "../datasets/Finger/FOESamples/Bad/27.bmp\n",
      "../datasets/Finger/FOESamples/Bad/28.bmp\n",
      "../datasets/Finger/FOESamples/Bad/29.bmp\n",
      "../datasets/Finger/FOESamples/Bad/30.bmp\n",
      "../datasets/Finger/FOESamples/Bad/31.bmp\n",
      "../datasets/Finger/FOESamples/Bad/32.bmp\n",
      "../datasets/Finger/FOESamples/Bad/33.bmp\n",
      "../datasets/Finger/FOESamples/Bad/34.bmp\n",
      "../datasets/Finger/FOESamples/Bad/35.bmp\n",
      "../datasets/Finger/FOESamples/Bad/36.bmp\n",
      "../datasets/Finger/FOESamples/Bad/37.bmp\n",
      "../datasets/Finger/FOESamples/Bad/38.bmp\n",
      "../datasets/Finger/FOESamples/Bad/39.bmp\n",
      "../datasets/Finger/FOESamples/Bad/40.bmp\n",
      "../datasets/Finger/FOESamples/Bad/41.bmp\n",
      "../datasets/Finger/FOESamples/Bad/42.bmp\n",
      "../datasets/Finger/FOESamples/Bad/43.bmp\n",
      "../datasets/Finger/FOESamples/Bad/44.bmp\n",
      "../datasets/Finger/FOESamples/Bad/45.bmp\n",
      "../datasets/Finger/FOESamples/Bad/46.bmp\n",
      "../datasets/Finger/FOESamples/Bad/47.bmp\n",
      "../datasets/Finger/FOESamples/Bad/48.bmp\n",
      "../datasets/Finger/FOESamples/Bad/49.bmp\n",
      "../datasets/Finger/FOESamples/Good/110.bmp\n",
      "../datasets/Finger/FOESamples/Good/111.bmp\n",
      "../datasets/Finger/FOESamples/Good/112.bmp\n",
      "../datasets/Finger/FOESamples/Good/113.bmp\n",
      "../datasets/Finger/FOESamples/Good/114.bmp\n",
      "../datasets/Finger/FOESamples/Good/115.bmp\n",
      "../datasets/Finger/FOESamples/Good/116.bmp\n",
      "../datasets/Finger/FOESamples/Good/117.bmp\n",
      "../datasets/Finger/FOESamples/Good/118.bmp\n",
      "../datasets/Finger/FOESamples/Good/119.bmp\n",
      "../datasets/Finger/synfin/v1/0.png\n",
      "../datasets/Finger/synfin/v1/1.png\n",
      "../datasets/Finger/synfin/v1/2.png\n",
      "../datasets/Finger/synfin/v1/3.png\n",
      "../datasets/Finger/synfin/v1/4.png\n",
      "../datasets/Finger/synfin/v1/5.png\n",
      "../datasets/Finger/synfin/v1/6.png\n",
      "../datasets/Finger/synfin/v1/7.png\n",
      "../datasets/Finger/synfin/v1/8.png\n",
      "../datasets/Finger/synfin/v1/9.png\n",
      "../datasets/Finger/synfin/v1/10.png\n",
      "../datasets/Finger/synfin/v1/11.png\n",
      "../datasets/Finger/synfin/v1/12.png\n",
      "../datasets/Finger/synfin/v1/13.png\n",
      "../datasets/Finger/synfin/v1/14.png\n",
      "../datasets/Finger/synfin/v1/15.png\n",
      "../datasets/Finger/synfin/v1/16.png\n",
      "../datasets/Finger/synfin/v1/17.png\n",
      "../datasets/Finger/synfin/v1/18.png\n",
      "../datasets/Finger/synfin/v1/19.png\n",
      "../datasets/Finger/synfin/v1/20.png\n",
      "../datasets/Finger/synfin/v1/21.png\n",
      "../datasets/Finger/synfin/v1/22.png\n",
      "../datasets/Finger/synfin/v1/23.png\n",
      "../datasets/Finger/synfin/v1/24.png\n",
      "../datasets/Finger/synfin/v1/25.png\n",
      "../datasets/Finger/synfin/v1/26.png\n",
      "../datasets/Finger/synfin/v1/27.png\n",
      "../datasets/Finger/synfin/v1/28.png\n",
      "../datasets/Finger/synfin/v1/29.png\n",
      "../datasets/Finger/synfin/v1/2530.png\n",
      "../datasets/Finger/synfin/v1/2531.png\n",
      "../datasets/Finger/synfin/v1/2532.png\n",
      "../datasets/Finger/synfin/v1/2533.png\n",
      "../datasets/Finger/synfin/v1/2534.png\n",
      "../datasets/Finger/synfin/v1/2535.png\n",
      "../datasets/Finger/synfin/v1/2536.png\n",
      "../datasets/Finger/synfin/v1/2537.png\n",
      "../datasets/Finger/synfin/v1/2538.png\n",
      "../datasets/Finger/synfin/v1/2539.png\n",
      "../datasets/Finger/synfin/v1/2540.png\n",
      "../datasets/Finger/synfin/v1/2541.png\n",
      "../datasets/Finger/synfin/v1/2542.png\n",
      "../datasets/Finger/synfin/v1/2543.png\n",
      "../datasets/Finger/synfin/v1/2544.png\n",
      "../datasets/Finger/synfin/v1/2545.png\n",
      "../datasets/Finger/synfin/v1/2546.png\n",
      "../datasets/Finger/synfin/v1/2547.png\n",
      "../datasets/Finger/synfin/v1/2548.png\n",
      "../datasets/Finger/synfin/v1/2549.png\n",
      "../datasets/Finger/synfin/v1/2550.png\n",
      "../datasets/Finger/synfin/v1/2551.png\n",
      "../datasets/Finger/synfin/v1/2552.png\n",
      "../datasets/Finger/synfin/v1/2553.png\n",
      "../datasets/Finger/synfin/v1/2554.png\n",
      "../datasets/Finger/synfin/v1/2555.png\n",
      "../datasets/Finger/synfin/v1/2556.png\n",
      "../datasets/Finger/synfin/v1/2557.png\n",
      "../datasets/Finger/synfin/v1/2558.png\n",
      "../datasets/Finger/synfin/v1/2559.png\n",
      "../datasets/Finger/synfin/v1/5060.png\n",
      "../datasets/Finger/synfin/v1/5061.png\n",
      "../datasets/Finger/synfin/v1/5062.png\n",
      "../datasets/Finger/synfin/v1/5063.png\n",
      "../datasets/Finger/synfin/v1/5064.png\n",
      "../datasets/Finger/synfin/v1/5065.png\n",
      "../datasets/Finger/synfin/v1/5066.png\n",
      "../datasets/Finger/synfin/v1/5067.png\n",
      "../datasets/Finger/synfin/v1/5068.png\n",
      "../datasets/Finger/synfin/v1/5069.png\n",
      "../datasets/Finger/synfin/v1/5070.png\n",
      "../datasets/Finger/synfin/v1/5071.png\n",
      "../datasets/Finger/synfin/v1/5072.png\n",
      "../datasets/Finger/synfin/v1/5073.png\n",
      "../datasets/Finger/synfin/v1/5074.png\n",
      "../datasets/Finger/synfin/v1/5075.png\n",
      "../datasets/Finger/synfin/v1/5076.png\n",
      "../datasets/Finger/synfin/v1/5077.png\n",
      "../datasets/Finger/synfin/v1/5078.png\n",
      "../datasets/Finger/synfin/v1/5079.png\n",
      "../datasets/Finger/synfin/v1/5080.png\n",
      "../datasets/Finger/synfin/v1/5081.png\n",
      "../datasets/Finger/synfin/v1/5082.png\n",
      "../datasets/Finger/synfin/v1/5083.png\n",
      "../datasets/Finger/synfin/v1/5084.png\n",
      "../datasets/Finger/synfin/v1/5085.png\n",
      "../datasets/Finger/synfin/v1/5086.png\n",
      "../datasets/Finger/synfin/v1/5087.png\n",
      "../datasets/Finger/synfin/v1/5088.png\n",
      "../datasets/Finger/synfin/v1/5089.png\n",
      "../datasets/Finger/synfin/v1/7590.png\n",
      "../datasets/Finger/synfin/v1/7591.png\n",
      "../datasets/Finger/synfin/v1/7592.png\n",
      "../datasets/Finger/synfin/v1/7593.png\n",
      "../datasets/Finger/synfin/v1/7594.png\n",
      "../datasets/Finger/synfin/v1/7595.png\n",
      "../datasets/Finger/synfin/v1/7596.png\n",
      "../datasets/Finger/synfin/v1/7597.png\n",
      "../datasets/Finger/synfin/v1/7598.png\n",
      "../datasets/Finger/synfin/v1/7599.png\n",
      "../datasets/Finger/synfin/v1/7600.png\n",
      "../datasets/Finger/synfin/v1/7601.png\n",
      "../datasets/Finger/synfin/v1/7602.png\n",
      "../datasets/Finger/synfin/v1/7603.png\n",
      "../datasets/Finger/synfin/v1/7604.png\n",
      "../datasets/Finger/synfin/v1/7605.png\n",
      "../datasets/Finger/synfin/v1/7606.png\n",
      "../datasets/Finger/synfin/v1/7607.png\n",
      "../datasets/Finger/synfin/v1/7608.png\n",
      "../datasets/Finger/synfin/v1/7609.png\n",
      "../datasets/Finger/synfin/v1/7610.png\n",
      "../datasets/Finger/synfin/v1/7611.png\n",
      "../datasets/Finger/synfin/v1/7612.png\n",
      "../datasets/Finger/synfin/v1/7613.png\n",
      "../datasets/Finger/synfin/v1/7614.png\n",
      "../datasets/Finger/synfin/v1/7615.png\n",
      "../datasets/Finger/synfin/v1/7616.png\n",
      "../datasets/Finger/synfin/v1/7617.png\n",
      "../datasets/Finger/synfin/v1/7618.png\n",
      "../datasets/Finger/synfin/v1/7619.png\n",
      "../datasets/Finger/synfin/v1/10120.png\n",
      "../datasets/Finger/synfin/v1/10121.png\n",
      "../datasets/Finger/synfin/v1/10122.png\n",
      "../datasets/Finger/synfin/v1/10123.png\n",
      "../datasets/Finger/synfin/v1/10124.png\n",
      "../datasets/Finger/synfin/v1/10125.png\n",
      "../datasets/Finger/synfin/v1/10126.png\n",
      "../datasets/Finger/synfin/v1/10127.png\n",
      "../datasets/Finger/synfin/v1/10128.png\n",
      "../datasets/Finger/synfin/v1/10129.png\n",
      "../datasets/Finger/synfin/v1/10130.png\n",
      "../datasets/Finger/synfin/v1/10131.png\n",
      "../datasets/Finger/synfin/v1/10132.png\n",
      "../datasets/Finger/synfin/v1/10133.png\n",
      "../datasets/Finger/synfin/v1/10134.png\n",
      "../datasets/Finger/synfin/v1/10135.png\n",
      "../datasets/Finger/synfin/v1/10136.png\n",
      "../datasets/Finger/synfin/v1/10137.png\n",
      "../datasets/Finger/synfin/v1/10138.png\n",
      "../datasets/Finger/synfin/v1/10139.png\n",
      "../datasets/Finger/synfin/v1/10140.png\n",
      "../datasets/Finger/synfin/v1/10141.png\n",
      "../datasets/Finger/synfin/v1/10142.png\n",
      "../datasets/Finger/synfin/v1/10143.png\n",
      "../datasets/Finger/synfin/v1/10144.png\n",
      "../datasets/Finger/synfin/v1/10145.png\n",
      "../datasets/Finger/synfin/v1/10146.png\n",
      "../datasets/Finger/synfin/v1/10147.png\n",
      "../datasets/Finger/synfin/v1/10148.png\n",
      "../datasets/Finger/synfin/v1/10149.png\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from foe_dataset2 import FOEDataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "\n",
    "real_path = '../datasets/Finger/FOESamples'\n",
    "synth_path = '../datasets/Finger/synfin/v1'\n",
    "\n",
    "dataset = FOEDataset(real_path, n_classes=256, patch_size=27, synth=False, subset=\"all\")\n",
    "# img = plt.imread(os.path.join(real_path,\"Good\",\"110.bmp\"))\n",
    "# fg = np.loadtxt(os.path.join(real_path,\"Good\",\"110.fg\"),skiprows=1)\n",
    "# gt = dataset.read_gt(os.path.join(real_path,\"Good\",\"110.gt\"))\n",
    "# plt.figure()\n",
    "# dataset.plot_grid(img,dataset.extract_grid_data(img, fg, gt))\n",
    "\n",
    "dataset2 = FOEDataset(synth_path, n_classes=256, patch_size=27, synth=True)\n",
    "# img = plt.imread(os.path.join(synth_path,\"200.png\"))\n",
    "# fg = np.loadtxt(os.path.join(synth_path,\"200.fg\"))\n",
    "# gt = dataset2.read_gt(os.path.join(synth_path,\"200.gt\"))\n",
    "# plt.figure()\n",
    "# dataset.plot_grid(img,dataset2.extract_grid_data(img, fg, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9aff7ac-0f4b-49bd-aa9f-4b523b3e206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_layers = torch.nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            torch.nn.BatchNorm2d(1),\n",
    "            torch.nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4 * 13 * 13, 512),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(256, 1),\n",
    "        )\n",
    "    \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self,m):\n",
    "        if type(m) == torch.nn.Linear:\n",
    "            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36890b09-c291-4a4d-b6ae-82d7ad48fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    train_loss, correct = 0, 0\n",
    "    i = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y = y.view((-1, 1))\n",
    "#         X = X.view((X.shape[0],1,X.shape[1],X.shape[2]))\n",
    "#         X = X.repeat(1,3,1,1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        i+=1\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         if batch % 100 == 0:\n",
    "#             loss, current = loss.item(), batch * len(X)\n",
    "#             print(f\"loss: {loss:>7f}  [{current:>5d}]\")\n",
    "    scheduler.step()\n",
    "    train_loss /= len(dataloader)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Training Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f}\")\n",
    "    return[train_loss, correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde38acb-e05d-4fdb-a70d-072f50d1290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    predd, yy = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.view(-1, 1)\n",
    "#             X = X.view((X.shape[0],1,X.shape[1],X.shape[2]))\n",
    "#             X = X.repeat(1,3,1,1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            predd.append(pred)\n",
    "            yy.append(y)\n",
    "            loss = loss_fn(pred, y.float())\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= len(dataloader)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    return[test_loss, correct, predd, yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f452c99a-5fc3-437b-be2f-ad509858bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Training Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.022452\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.055920\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Training Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.022425\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.059542\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Training Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.022402\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.061535\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Training Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.022386\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.063295\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Training Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.022372\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.064841\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec86a65ee579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mtrain_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtest_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtrain_res3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5e8073aad399>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         X = X.view((X.shape[0],1,X.shape[1],X.shape[2]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # import torchvision.models as models\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"Using {} device\".format(device))\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# N = len(dataset)\n",
    "# batch_size = 128\n",
    "# train_size = round(N*0.9)\n",
    "# val_size = round(N*0.1)\n",
    "# test_size = round(N*0.1)\n",
    "# training_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "# training_data2, test_data2 = torch.utils.data.random_split(dataset2, [len(dataset2), 0], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# folds = 1\n",
    "# test_dataloader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "# for f in range(folds):\n",
    "#     model = NeuralNetwork().to(device)\n",
    "# #     model = models.alexnet(pretrained=True)\n",
    "# #     new_classifier = torch.nn.Sequential(*list(model.classifier.children())+[torch.nn.ReLU(inplace=True),torch.nn.Linear(1000, 1),])\n",
    "# #     model.classifier = new_classifier\n",
    "# #     if torch.cuda.is_available():\n",
    "# #         model.cuda()\n",
    "# #     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 0.0001, 0.1)\n",
    "#     train_dataloader =  torch.utils.data.DataLoader(training_data, batch_size=batch_size)\n",
    "#     val_dataloader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#     epochs = 500\n",
    "#     train_res = []\n",
    "#     test_res = []\n",
    "#     for t in range(epochs):\n",
    "#         print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#         train_ret = train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "#         test_ret = test(val_dataloader, model)\n",
    "#         train_res.append(train_ret)\n",
    "#         test_res.append(test_ret)\n",
    "#     print(\"Done!\")\n",
    "\n",
    "# for f in range(folds):\n",
    "#     model2 = NeuralNetwork().to(device)\n",
    "# #     model2 = models.alexnet(pretrained=True)\n",
    "# #     new_classifier = torch.nn.Sequential(*list(model2.classifier.children())+[torch.nn.ReLU(inplace=True),torch.nn.Linear(1000, 1),])\n",
    "# #     model2.classifier = new_classifier\n",
    "# #     if torch.cuda.is_available():\n",
    "# #         model2.cuda()\n",
    "# #     optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "#     optimizer = torch.optim.SGD(model2.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 0.0001, 0.01)\n",
    "#     train_dataloader =  torch.utils.data.DataLoader(training_data2, batch_size=batch_size)\n",
    "#     val_dataloader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#     epochs = 500\n",
    "#     train_res2 = []\n",
    "#     test_res2 = []\n",
    "#     for t in range(epochs):\n",
    "#         print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#         train_ret = train(train_dataloader, model2, loss_fn, optimizer, scheduler)\n",
    "#         test_ret = test(val_dataloader, model2)\n",
    "#         train_res2.append(train_ret)\n",
    "#         test_res2.append(test_ret)\n",
    "#     print(\"Done!\")\n",
    "    \n",
    "# for f in range(folds):\n",
    "#     model3 = NeuralNetwork().to(device)\n",
    "# #     model2 = models.alexnet(pretrained=True)\n",
    "# #     new_classifier = torch.nn.Sequential(*list(model2.classifier.children())+[torch.nn.ReLU(inplace=True),torch.nn.Linear(1000, 1),])\n",
    "# #     model2.classifier = new_classifier\n",
    "# #     if torch.cuda.is_available():\n",
    "# #         model2.cuda()\n",
    "# #     optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "#     optimizer = torch.optim.SGD(model3.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 0.0001, 0.01)\n",
    "#     train_dataloader =  torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([training_data, training_data2]), batch_size=batch_size)\n",
    "#     val_dataloader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#     epochs = 500\n",
    "#     train_res3 = []\n",
    "#     test_res3 = []\n",
    "for t in range(500):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_ret = train(train_dataloader, model3, loss_fn, optimizer, scheduler)\n",
    "    test_ret = test(val_dataloader, model3)\n",
    "    train_res3.append(train_ret)\n",
    "    test_res3.append(test_ret)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef4c1b7-4da9-4dd9-87cb-72a056a00b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ac4cf06cbc4cb58270ab111790ffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb3ac93794a4cdf8a64e3e60360e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d4e31f8c949a>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  plt.plot(np.array(test_res2)[:,0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f1bcdbc2f2447ea5f7591e77cb6f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d4e31f8c949a>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  plt.plot(np.array(test_res3)[:,0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7715f03370>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(train_res)[:,0])\n",
    "plt.plot(np.array(test_res)[:,0])\n",
    "plt.figure()\n",
    "plt.plot(np.array(train_res2)[:,0])\n",
    "plt.plot(np.array(test_res2)[:,0])\n",
    "plt.figure()\n",
    "plt.plot(np.array(train_res3)[:,0])\n",
    "plt.plot(np.array(test_res3)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0d56bb-5620-4b47-a1b7-bb2de641fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03868118962873405\n",
      "0.04196266026546558\n",
      "0.021687816271861626\n",
      "0.06593483418226243\n",
      "0.02237168367403422\n",
      "0.04735254059235255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-14d87a146fce>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.array(test_res2)[:,0].min())\n",
      "<ipython-input-15-14d87a146fce>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.array(test_res3)[:,0].min())\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_res)[:,0].min())\n",
    "print(np.array(test_res)[:,0].min())\n",
    "print(np.array(train_res2)[:,0].min())\n",
    "print(np.array(test_res2)[:,0].min())\n",
    "print(np.array(train_res3)[:,0].min())\n",
    "print(np.array(test_res3)[:,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a324768f-193e-46c3-b1fa-ed8fa58ee7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 26.7%, Avg loss: 0.072242\n",
      "tensor(0.7391, device='cuda:0')\n",
      "tensor(-0.5993, device='cuda:0')\n",
      "torch.Size([247560, 1])\n",
      "tensor(0.4944, device='cuda:0', dtype=torch.float64) tensor(-0.5000, device='cuda:0', dtype=torch.float64)\n",
      "tensor(-0.0045, device='cuda:0', dtype=torch.float64) tensor(0.3314, device='cuda:0', dtype=torch.float64)\n",
      "tensor(-0.5000, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2152, device='cuda:0')\n",
      "tensor(-0.9942, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8dea763dca4109bd95460c6d6b5410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 27, 27) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ebd8a852415c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2903\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2904\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5607\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5609\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5610\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/app/env/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    708\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 709\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    710\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 27, 27) for image data"
     ]
    }
   ],
   "source": [
    "train_dataloader =  torch.utils.data.DataLoader(training_data2, batch_size=batch_size)\n",
    "test_loss, correct, predd, yy = test(train_dataloader, model)\n",
    "# aaa = np.array([])\n",
    "# bbb = np.array([])\n",
    "# for p in predd: aaa = np.append(aaa, p.cpu().data.numpy().flatten())\n",
    "# for y in yy: bbb = np.append(bbb, y.cpu().data.numpy().flatten())\n",
    "# ccc = np.power(np.mean(np.power((aaa-bbb)*180%90,2)),0.5)\n",
    "# print(aaa.shape, bbb.shape, test_loss, ccc)\n",
    "\n",
    "print(predd[0].transpose(0,1).max())\n",
    "print(predd[0].transpose(0,1).min())\n",
    "print(torch.cat(yy).shape)\n",
    "print(torch.cat(yy).max(), torch.cat(yy).min())\n",
    "print(torch.cat(yy).mean(), torch.cat(yy).std())\n",
    "print(torch.cat(yy).min())\n",
    "print(torch.cat(predd).max())\n",
    "print(torch.cat(predd).min())\n",
    "plt.figure()\n",
    "plt.imshow(dataset.data[:,4][3000])\n",
    "print(dataset.data[:,3][3000])\n",
    "print(torch.cat(yy)[3000])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7b3e6d3-cc21-47f4-b9cb-85b93f3fa29b",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.hist(yy[0])\n",
    "plt.figure()\n",
    "plt.hist(np.abs((aaa-bbb))*180%90,180)\n",
    "plt.figure()\n",
    "plt.hist(np.power((aaa-bbb)*180%90,2),180)\n",
    "plt.figure()\n",
    "plt.hist(np.power((aaa-bbb)*180,2),180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058450d0-17b9-4b44-b9eb-d08464a0757f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "834e3117-2d6b-4332-8216-78563620ac5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00392fd9-41a3-4a84-b9cb-025d124f5ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
